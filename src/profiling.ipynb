{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.nn import SimplePeriodicNetwork\n",
    "\n",
    "batch_size = 10 \n",
    "radial_cutoff = 5\n",
    "\n",
    "net = SimplePeriodicNetwork(\n",
    "        irreps_in=\"1x1o\",  \n",
    "        irreps_out=\"1x0e\",  # Single scalar (L=0 and even parity) to output (for example) energy\n",
    "        max_radius=radial_cutoff, # Cutoff radius for convolution\n",
    "        num_neighbors=10.0,  # scaling factor based on the typical number of neighbors\n",
    "        pool_nodes=True,  # We pool nodes to predict total energy\n",
    "    )\n",
    "\n",
    "criterion = nn.MSELoss()  # Example: Mean Squared Error\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "# project_name = 'LiCondEquivariantModel'\n",
    "project_name = None\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sevenn.train.dataload import graph_build\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sevenn.train.dataset import AtomGraphDataset\n",
    "from ase.calculators.singlepoint import SinglePointCalculator\n",
    "from sevenn.train.dataload import _set_atoms_y\n",
    "from typing import Any, List, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.loader.dataloader import Collater\n",
    "import sevenn\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def assign_dummy_y(atoms):\n",
    "    dummy = {'energy': np.nan, 'free_energy': np.nan}\n",
    "    dummy['forces'] = np.full((len(atoms), 3), np.nan) \n",
    "    dummy['stress'] = np.full((6,), np.nan)  \n",
    "    calc = SinglePointCalculator(atoms, **dummy)\n",
    "    atoms = calc.get_atoms()\n",
    "    return calc.get_atoms()\n",
    "\n",
    "\n",
    "class SevenNetPropertiesPredictor():\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_name,\n",
    "        ):\n",
    "\n",
    "        checkpoint = sevenn.util.pretrained_name_to_path(config_name)\n",
    "        sevennet_model, sevennet_config = sevenn.util.model_from_checkpoint(checkpoint)\n",
    "\n",
    "        self.sevennet_model = sevennet_model\n",
    "        self.sevennet_config = sevennet_config\n",
    "\n",
    "\n",
    "    def predict(self, batch: List[Any]) -> List[Any]:\n",
    "\n",
    "        atoms_list = []    \n",
    "        atoms_len = []\n",
    "        for atoms in batch:\n",
    "            atoms_list.append(assign_dummy_y(atoms))\n",
    "            atoms_len.append(atoms.get_positions().shape[0])\n",
    "\n",
    "        atoms_list = _set_atoms_y(atoms_list)\n",
    "\n",
    "        sevennet_data_list = graph_build(\n",
    "                    atoms_list,\n",
    "                    self.sevennet_config['cutoff'],\n",
    "                    num_cores=max(1, self.sevennet_config['_num_workers']),\n",
    "                    y_from_calc=False,\n",
    "                )\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        sevennet_inference_set = AtomGraphDataset(sevennet_data_list, self.sevennet_config['cutoff'])\n",
    "        sevennet_inference_set.x_to_one_hot_idx(self.sevennet_config['_type_map'])\n",
    "        sevennet_inference_set.toggle_requires_grad_of_data(sevenn._keys.POS, True)\n",
    "        sevennet_infer_list = sevennet_inference_set.to_list()\n",
    "\n",
    "        sevennet_batch = DataLoader(sevennet_infer_list, batch_size=len(sevennet_infer_list), shuffle=False)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        create_dataset_time = end_time - start_time\n",
    "\n",
    "        (sevennet_batch,) = sevennet_batch\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        sevennet_output = self.sevennet_model(sevennet_batch).detach().to(\"cpu\")\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        sevennet_model_inference = end_time - start_time\n",
    "\n",
    "        forces = []\n",
    "        energies = []\n",
    "        total_lenn = 0\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for index, lenn in enumerate(atoms_len):\n",
    "            forces.append(sevennet_output.inferred_force[total_lenn:total_lenn+lenn, :].clone().detach())\n",
    "            energies.append(sevennet_output.inferred_total_energy[index].clone().detach())\n",
    "            total_lenn += lenn\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        build_results = end_time - start_time\n",
    "\n",
    "        return  {\n",
    "            'forces': forces,\n",
    "            'energy': energies,\n",
    "        }, create_dataset_time, sevennet_model_inference, build_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:00<00:00, 475.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from modules.dataset import build_dataset \n",
    "\n",
    "dataset = build_dataset(csv_path = '../data/sevennet_slopes.csv')\n",
    "checkpoint_name = '7net-0'\n",
    "SevennetPredictor = SevenNetPropertiesPredictor(checkpoint_name)\n",
    "\n",
    "batch_size = 150\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/container-user/.local/lib/python3.11/site-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n",
      "graph_build (1): 100%|██████████| 150/150 [00:05<00:00, 26.98it/s]\n",
      "graph_build (1): 100%|██████████| 29/29 [00:01<00:00, 28.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import time\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader.dataloader import Collater\n",
    "from tqdm import tqdm\n",
    "import ase.io\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "\n",
    "def set_noise_to_structures(batch):\n",
    "    for atoms in batch:\n",
    "        positions = atoms.get_positions() \n",
    "        noise = np.random.normal(loc=0, scale=1, size=positions.shape)    \n",
    "        atoms.set_positions(positions + noise)\n",
    "    return batch\n",
    "\n",
    "graph_building = []\n",
    "model_evaluation = []\n",
    "sevennet_property_predictor = []\n",
    "batch_time = []\n",
    "\n",
    "create_dataset_sevennet = []\n",
    "model_inference_sevennet = []\n",
    "build_results_sevennet = []\n",
    "\n",
    "for batch in dataloader:\n",
    "\n",
    "    batch_start = time.perf_counter()\n",
    "\n",
    "    atoms_batch = batch.x['atoms']\n",
    "    noise_structures_batch = set_noise_to_structures(deepcopy(atoms_batch))\n",
    "    log_diffusion_batch = batch.x['log_diffusion']\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    properties_batch, create_dataset_time, model_inference_time, build_results_time = SevennetPredictor.predict(noise_structures_batch)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    create_dataset_sevennet.append(create_dataset_time)\n",
    "    model_inference_sevennet.append(model_inference_time)\n",
    "    build_results_sevennet.append(build_results_time)\n",
    "\n",
    "    sevennet_property_predictor.append(end_time - start_time)\n",
    "\n",
    "    atoms_list = []    \n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for log_diffusion, noise_structures, forces in zip(log_diffusion_batch, noise_structures_batch, properties_batch['forces']):\n",
    "        atoms = noise_structures\n",
    "        edge_src, edge_dst, edge_shift = ase.neighborlist.neighbor_list(\"ijS\", a=atoms, cutoff= 5, self_interaction=True) \n",
    "\n",
    "        data = Data(\n",
    "                pos=torch.tensor(atoms.get_positions(), dtype=torch.float32),\n",
    "                x=forces,\n",
    "                lattice=torch.tensor(atoms.cell.array, dtype=torch.float32).unsqueeze(0), \n",
    "                edge_index=torch.stack([torch.LongTensor(edge_src), torch.LongTensor(edge_dst)], dim=0),\n",
    "                edge_shift=torch.tensor(edge_shift, dtype=torch.float32),\n",
    "                target = log_diffusion\n",
    "        )\n",
    "\n",
    "        atoms_list.append(data)\n",
    "\n",
    "    atoms_batch = Batch.from_data_list(atoms_list)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    graph_building.append(end_time - start_time)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    outputs = net(atoms_batch)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    batch_end = time.perf_counter()\n",
    "\n",
    "    batch_time.append(batch_end - batch_start)\n",
    "    model_evaluation.append(end_time - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_building: 2.6488343398086727\n",
      "model_evaluation: 18.829915893729776\n",
      "create_dataset_sevennet: 0.008556838845834136\n",
      "model_inference_sevennet: 40.66284448839724\n",
      "build_results_sevennet: 0.0020445329137146473\n",
      "batch_time: 64.89997762395069\n"
     ]
    }
   ],
   "source": [
    "print('graph_building:', np.array(graph_building).mean())\n",
    "print('model_evaluation:', np.array(model_evaluation).mean())\n",
    "\n",
    "print('create_dataset_sevennet:', np.array(create_dataset_sevennet).mean())\n",
    "print('model_inference_sevennet:', np.array(model_inference_sevennet).mean())\n",
    "print('build_results_sevennet:', np.array(build_results_sevennet).mean())\n",
    "\n",
    "print('batch_time:', np.array(batch_time).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
