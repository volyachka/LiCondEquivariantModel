# General settings
experiment_name: "superionic_toy"
comment: "toy dataset"
output_dir: "/mnt/hdd/turchina/saved_models" 
 
# Data configuration
data:
  name: "toy_dataset"
  root_folder: "/mnt/hdd/maevskiy/SuperionicToy-runs/v0-2025-01-29"
  noise_std: 0.1 
  batch_size: 10
  num_workers: 4  
  test_size: 0.2
  random_state: 42
  clip_value: 0.01
  upd_neigh_style: "update_class"

model:
  mix_properites: False
  layers: 2
  radial_cutoff: 5
  num_neighbors: 50
  number_of_basis: 1
  predict_importance: False
  pool_nodes: False
  num_nodes: 1.0

scheduler:
  constant_lr: True
  warmup_scheduler: "LinearLR"
  warmup_epochs: 5
  warmup_decay: 0.01
  main_scheduler: "CosineAnnealingLR"

optimizer:
  name: "Adam"
  learning_rate: 0.0001

# Training hyperparameters
training:
  num_noisy_configurations: 2
  criterion: "MSELoss"  
  num_epochs: 500
  device: "cuda:1"
  save_model_every_n_epochs: 20
  forces_divided_by_mass: True
  use_displacements: False
  use_energies: False
  softmax_within_single_structure_by_atoms: False
  softmax_within_single_atom_by_configurations: True
  softmax_within_configurations: False
  predict_per_atom: True

property_predictor:
  name: "superionic_toy"
  property_config: {}
wandb:
  verbose: True
  project_name: "LiCondEquivariantModel"
  entity_name: "licondequvariantmodel"

